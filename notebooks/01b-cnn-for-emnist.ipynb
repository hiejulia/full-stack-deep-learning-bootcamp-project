{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from importlib.util import find_spec\n",
    "if find_spec(\"text_recognizer\") is None:\n",
    "    import sys\n",
    "    sys.path.append('..')\n",
    "\n",
    "from text_recognizer.datasets.emnist_dataset import EmnistDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMNIST Dataset\n",
      "Num classes: 80\n",
      "Mapping: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J', 20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T', 30: 'U', 31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z', 36: 'a', 37: 'b', 38: 'c', 39: 'd', 40: 'e', 41: 'f', 42: 'g', 43: 'h', 44: 'i', 45: 'j', 46: 'k', 47: 'l', 48: 'm', 49: 'n', 50: 'o', 51: 'p', 52: 'q', 53: 'r', 54: 's', 55: 't', 56: 'u', 57: 'v', 58: 'w', 59: 'x', 60: 'y', 61: 'z', 62: ' ', 63: '!', 64: '\"', 65: '#', 66: '&', 67: \"'\", 68: '(', 69: ')', 70: '*', 71: '+', 72: ',', 73: '-', 74: '.', 75: '/', 76: ':', 77: ';', 78: '?', 79: '_'}\n",
      "Input shape: [28, 28]\n",
      "\n",
      "(84074, 28, 28) (84074, 80)\n",
      "(13947, 28, 28) (13947, 80)\n"
     ]
    }
   ],
   "source": [
    "dataset = EmnistDataset(subsample_fraction=0.25)\n",
    "dataset.load_or_generate_data()\n",
    "print(dataset)\n",
    "print(dataset.x_train.shape, dataset.y_train.shape)\n",
    "print(dataset.x_test.shape, dataset.y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "expand_dims (Lambda)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 80)                10320     \n",
      "=================================================================\n",
      "Total params: 1,634,896\n",
      "Trainable params: 1,634,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# -------LENET------\n",
    "from text_recognizer.networks.lenet import lenet\n",
    "\n",
    "network = lenet(dataset.input_shape, output_shape=(dataset.num_classes, 1))\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1314/1314 [==============================] - 20s 15ms/step - loss: 0.2816 - accuracy: 0.9345 - val_loss: 0.0562 - val_accuracy: 0.9833\n",
      "Epoch 2/5\n",
      "1314/1314 [==============================] - 6s 4ms/step - loss: 0.0662 - accuracy: 0.9804 - val_loss: 0.0365 - val_accuracy: 0.9889\n",
      "Epoch 3/5\n",
      "1314/1314 [==============================] - 6s 4ms/step - loss: 0.0466 - accuracy: 0.9860 - val_loss: 0.0352 - val_accuracy: 0.9905\n",
      "Epoch 4/5\n",
      "1314/1314 [==============================] - 6s 4ms/step - loss: 0.0373 - accuracy: 0.9889 - val_loss: 0.0292 - val_accuracy: 0.9915\n",
      "Epoch 5/5\n",
      "1314/1314 [==============================] - 6s 4ms/step - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.0306 - val_accuracy: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f886c072150>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.compile(optimizer='sgd', loss='categorical_crossentropy', metrics='accuracy')\n",
    "network.fit(\n",
    "    x=dataset.x_train,\n",
    "    y=dataset.y_train,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    validation_data=(dataset.x_test, dataset.y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n",
      "[[9.99999881e-01 8.04929214e-12 7.04592438e-08 1.50007502e-12\n",
      "  2.19322199e-11 1.06680595e-10 1.00794795e-09 1.53098159e-11\n",
      "  1.44311104e-13 2.55953690e-16 7.89550852e-14 4.83885994e-15\n",
      "  1.83673610e-15 6.49945048e-18 5.02020758e-16 5.86758376e-12\n",
      "  1.82197581e-16 8.72858219e-15 1.71123361e-18 9.04258917e-16\n",
      "  1.90967135e-14 2.65879655e-17 6.61706321e-16 2.67261456e-18\n",
      "  2.62863665e-14 3.56004904e-17 2.56579595e-14 7.47674977e-16\n",
      "  6.07827336e-17 2.06184588e-16 2.58166172e-14 1.26347041e-18\n",
      "  2.54738192e-15 3.23505943e-19 2.34137969e-11 1.45513349e-14\n",
      "  1.71233809e-13 2.57681849e-16 1.28874049e-12 5.36686682e-15\n",
      "  4.88973393e-17 1.05590820e-15 2.28668360e-15 8.28977197e-19\n",
      "  2.82996537e-14 1.03052781e-15 2.33458899e-14 2.41450066e-15\n",
      "  7.87818991e-15 1.53353580e-11 4.72213093e-17 1.79844153e-17\n",
      "  1.31031984e-15 1.16631834e-12 7.82538006e-16 1.11099817e-15\n",
      "  1.69132320e-14 8.32786933e-19 8.21636186e-17 2.01583333e-11\n",
      "  7.76110720e-16 2.75385454e-20 1.01259130e-14 6.19342633e-18\n",
      "  7.20859830e-12 6.39739633e-17 1.68899969e-13 4.98640673e-16\n",
      "  3.47947801e-17 1.07689864e-11 1.68758593e-17 1.48350991e-19\n",
      "  2.83468417e-16 3.62903378e-16 3.56404802e-11 5.07289273e-18\n",
      "  6.97691443e-17 8.91541352e-16 2.66899458e-13 1.19877016e-17]]\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_example = dataset.x_test[0:1]\n",
    "plt.matshow(x_example[0])\n",
    "\n",
    "x_example = np.expand_dims(x_example, -1)\n",
    "print(x_example.shape)\n",
    "preds = network.predict(x_example)\n",
    "print(preds)\n",
    "\n",
    "ind = np.argmax(preds)\n",
    "print(ind)\n",
    "\n",
    "print(dataset.mapping[ind])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('fsdl-text-recognizer': conda)",
   "language": "python",
   "name": "python37764bitfsdltextrecognizercondadeddc9485e524fe5bef8d396f447eae4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}